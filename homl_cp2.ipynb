{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homl_cp1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khlose/homl_ageron/blob/master/homl_cp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OTOINK8NSsJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "62d7f83a-e662-4b84-ef8f-381e59769b0c"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "DATA LOADING AND SPLITTING PRACTICE\n",
        "'''\n",
        "\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "import pandas as pd\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\",\"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
        "  if not os.path.isdir(housing_path):\n",
        "    os.makedirs(housing_path)\n",
        "  \n",
        "  tgz_path = os.path.join(housing_path,\"housing.tgz\")\n",
        "  \n",
        "  urllib.request.urlretrieve(housing_url,tgz_path)\n",
        "  housing_tgz = tarfile.open(tgz_path)\n",
        "  housing_tgz.extractall(path=housing_path)\n",
        "  housing_tgz.close()\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "  csv_path = os.path.join(housing_path,\"housing.csv\")\n",
        "  return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fetch_housing_data()\n",
        "housing = load_housing_data()\n",
        "\n",
        "\n",
        "#housing.head()\n",
        "\n",
        "#housing[\"ocean_proximity\"].value_counts()\n",
        "#housing.describe()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#housing.hist(bins=50,figsize=(20,15))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "  return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test(data,test_ratio,id_column):\n",
        "  \n",
        "  ids = data[id_column]\n",
        "  in_test_set = ids.apply(lambda id_:test_set_check(id_,test_ratio))\n",
        "  \n",
        "  return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#housing_with_id = housing.reset_index()\n",
        "#housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "#train,test = split_train_test(housing_with_id,0.2,\"index\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set,test_set = train_test_split(housing,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"]/1.5)\n",
        "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0,inplace=True)\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\n",
        "\n",
        "for train_index,test_index in split.split(housing,housing[\"income_cat\"]):\n",
        "  strat_train_data = housing.loc[train_index]\n",
        "  strat_test_data = housing.loc[test_index]\n",
        "\n",
        "  \n",
        "print(strat_train_data.count())  \n",
        "\n",
        "\n",
        "#basically loop twice, first loop is start_train_data loop\n",
        "#and second is strat_test_data loop\n",
        "for set_ in (strat_train_data,strat_test_data):\n",
        "  #print(set_.count())\n",
        "  \n",
        "  set_.drop(\"income_cat\",axis=1,inplace=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "longitude             16512\n",
            "latitude              16512\n",
            "housing_median_age    16512\n",
            "total_rooms           16512\n",
            "total_bedrooms        16354\n",
            "population            16512\n",
            "households            16512\n",
            "median_income         16512\n",
            "median_house_value    16512\n",
            "ocean_proximity       16512\n",
            "income_cat            16512\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uxDmb9efRyGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Data extraction practice\n",
        "'''\n",
        "\n",
        "#separating numerical and non-numerical data\n",
        "\n",
        "def separate_numerical(data):\n",
        "  cloned = data.copy()\n",
        "  \n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  numerical = cloned.drop(columns=object_list,axis=1)\n",
        "  \n",
        "  nonnumer = cloned[object_list]\n",
        "  \n",
        "  return numerical,nonnumer\n",
        "\n",
        "def separate_numerical_columns(data):\n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  numerical_list = list(data.select_dtypes(exclude=['object']).columns)\n",
        "  \n",
        "  return numerical_list, object_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66f87MDBlx75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "VISUALIZATION PRACTICE\n",
        "'''\n",
        "\n",
        "housing = strat_train_data.copy()\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        "\n",
        "#corr_matrix[\"median_house_value\"].sort_values()\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "#attributes = [\"median_house_value\",\"median_income\",\"total_rooms\",\"housing_median_age\"]\n",
        "\n",
        "#scatter_matrix(housing[attributes])\n",
        "\n",
        "#housing.plot(kind=\"scatter\",x=\"median_income\",y=\"median_house_value\",alpha=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pH1pmhezl46s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "CORRELATION MATRIX PRACTICE\n",
        "'''\n",
        "\n",
        "housing[\"room_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
        "\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "\n",
        "housing[\"populations_per_household\"] = housing[\"population\"]/housing[\"households\"]\n",
        "\n",
        "#corr_matrix = housing.corr()\n",
        "#corr_matrix[\"median_house_value\"].sort_values()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TViuwwHFp_Ia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "Imputer and Encoder practices\n",
        "'''\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def imputeData(data):\n",
        "  \n",
        "  ret_data = data.copy()\n",
        "  \n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  ret_data.drop(columns=object_list,axis=1,inplace=True)\n",
        "\n",
        "  imputer = SimpleImputer(strategy=\"median\")\n",
        "  imputer.fit(ret_data)\n",
        "  \n",
        "  X = imputer.transform(ret_data)\n",
        "\n",
        "  ret_data = pd.DataFrame(X,columns=ret_data.columns)\n",
        "  \n",
        "  #attach back the column with object\n",
        "  \n",
        "  wo_object =ret_data.copy()\n",
        "  \n",
        "  for column in object_list:\n",
        "    ret_data[column] = data[column]\n",
        "    \n",
        "  #return dataframe without object column and a frame WITH object column\n",
        "  return ret_data\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "#this will one-hot encode Panda Dataframe\n",
        "def encodeProx(data):\n",
        "  \n",
        "  ret_data = data.copy()\n",
        "  cat_encoder = OneHotEncoder(categories='auto')\n",
        "  #fill missing categorical value with just missing\n",
        "  \n",
        "  \n",
        "  object_list = list(ret_data.select_dtypes(include=['object']).columns)\n",
        "  '''for col in object_list:\n",
        "    ret_data[col].fillna('Missing',inplace=True)  \n",
        "    '''\n",
        "  #print(pd.isnull(ret_data).sum())\n",
        "  onehot = pd.get_dummies(ret_data,dummy_na=True)\n",
        "  #print(ret_data[\"ocean_proximity\"].values)\n",
        " \n",
        "  return onehot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5zXQaaHC77e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Transformer class inheritance practice\n",
        "\n",
        "'''\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n",
        "rooms_ix,bedrooms_ix,population_ix,households_ix = 3,4,5,6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  def __init__(self, add_bedrooms_per_room = True):\n",
        "    self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    \n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self,X,y=None):\n",
        "    rooms_per_household = X[:,rooms_ix] / X[:,households_ix]\n",
        "    population_per_household = X[:,population_ix]/X[:,households_ix]\n",
        "    if(self.add_bedrooms_per_room):\n",
        "      bedrooms_per_room  = X[:,bedrooms_ix] / X[:,rooms_ix]\n",
        "      return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n",
        "    else:\n",
        "      return np.c_[X,rooms_per_household,population_per_household]\n",
        "    \n",
        "    \n",
        "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
        "  def __init__(self,attribute_names):\n",
        "    self.attribute_names = attribute_names\n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  def transform(self,X):\n",
        "    return X[self.attribute_names].values\n",
        "    \n",
        "\n",
        "class CategoricalOnehotEncoder(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  def __init__(self,encoding=\"onehot\"):\n",
        "    self.encoding = encoding\n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  def transform(self,X,y=None):\n",
        "    \n",
        "    x_series = X[X.columns[0]]\n",
        "    x_cat_enc,x_cat_arr = x_series.factorize()\n",
        "    encoder = OneHotEncoder()\n",
        "    x_1hot = encoder.fit_transform(x_cat_enc.reshape(-1,1))\n",
        "    return x_1hot\n",
        "    \n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P47hilNpQQah",
        "colab_type": "code",
        "outputId": "47325b1d-9c66-4973-f9f3-2efc4d77a5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Pipelining practice\n",
        "'''\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#pipeline\n",
        "#estimator at all but last must be transfomer\n",
        "#ie. they must have fit_transform\n",
        "\n",
        "#this is numerical pipeline => input data must be numerical data\n",
        "#this pipeline does not have dataframe selector, we make use of the\n",
        "#separate_numerical function feed in numerical data\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('attribs_augment',CombinedAttributesAdder()),\n",
        "    #feature scaling transformer using stdev\n",
        "    ('std_scaler',StandardScaler())\n",
        "])\n",
        "\n",
        "housing_num,housing_non_num = separate_numerical(housing)\n",
        "#numerical_col,object_col = separate_numerical_columns(housing)\n",
        "\n",
        "#note you can do housing['ocean_proximity'].factorize because\n",
        "#housing['ocean_proximity'] will return a Panda serie\n",
        "#while housing[ ['ocean_proximity'] ] returns a Panda DataFrame\n",
        "#housing[object_col] => housing[['ocean_proximity']]\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
        "\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    #we dont need to use selector, another function has done it\n",
        "    #('selector',DataFrameSelector),\n",
        "    ('encoder', CategoricalOnehotEncoder(encoding='onehot'))\n",
        "])\n",
        "\n",
        "housing_cat_tr = cat_pipeline.fit_transform(housing_non_num)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wc6SrHWGpddm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Scrap page\n",
        "'''\n",
        "\n",
        "\n",
        "#reset\n",
        "housing = strat_train_data.copy()\n",
        "\n",
        "housing_pred = strat_train_data.drop(\"median_house_value\",axis=1)\n",
        "housing_label = strat_train_data[\"median_house_value\"].copy()\n",
        "\n",
        "\n",
        "\n",
        "housing_tr_reg = imputeData(housing_pred)\n",
        "\n",
        "onehotted = encodeProx(housing_tr_reg)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}