{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homl_cp1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khlose/homl_ageron/blob/master/homl_cp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTOINK8NSsJF",
        "colab_type": "code",
        "outputId": "8e1d818f-1d41-43d1-f3bd-035c374ebd06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "'''\n",
        "DATA LOADING AND SPLITTING PRACTICE\n",
        "'''\n",
        "\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "import pandas as pd\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\",\"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
        "  if not os.path.isdir(housing_path):\n",
        "    os.makedirs(housing_path)\n",
        "  \n",
        "  tgz_path = os.path.join(housing_path,\"housing.tgz\")\n",
        "  \n",
        "  urllib.request.urlretrieve(housing_url,tgz_path)\n",
        "  housing_tgz = tarfile.open(tgz_path)\n",
        "  housing_tgz.extractall(path=housing_path)\n",
        "  housing_tgz.close()\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "  csv_path = os.path.join(housing_path,\"housing.csv\")\n",
        "  return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fetch_housing_data()\n",
        "housing = load_housing_data()\n",
        "\n",
        "\n",
        "#housing.head()\n",
        "\n",
        "#housing[\"ocean_proximity\"].value_counts()\n",
        "#housing.describe()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#housing.hist(bins=50,figsize=(20,15))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "  return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test(data,test_ratio,id_column):\n",
        "  \n",
        "  ids = data[id_column]\n",
        "  in_test_set = ids.apply(lambda id_:test_set_check(id_,test_ratio))\n",
        "  \n",
        "  return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#housing_with_id = housing.reset_index()\n",
        "#housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "#train,test = split_train_test(housing_with_id,0.2,\"index\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set,test_set = train_test_split(housing,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"]/1.5)\n",
        "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0,inplace=True)\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\n",
        "\n",
        "for train_index,test_index in split.split(housing,housing[\"income_cat\"]):\n",
        "  strat_train_data = housing.loc[train_index]\n",
        "  strat_test_data = housing.loc[test_index]\n",
        "\n",
        "  \n",
        "print(strat_train_data.count())  \n",
        "\n",
        "\n",
        "#basically loop twice, first loop is start_train_data loop\n",
        "#and second is strat_test_data loop\n",
        "for set_ in (strat_train_data,strat_test_data):\n",
        "  #print(set_.count())\n",
        "  \n",
        "  set_.drop(\"income_cat\",axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "longitude             16512\n",
            "latitude              16512\n",
            "housing_median_age    16512\n",
            "total_rooms           16512\n",
            "total_bedrooms        16354\n",
            "population            16512\n",
            "households            16512\n",
            "median_income         16512\n",
            "median_house_value    16512\n",
            "ocean_proximity       16512\n",
            "income_cat            16512\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxDmb9efRyGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Data extraction practice\n",
        "'''\n",
        "\n",
        "#separating numerical and non-numerical data\n",
        "\n",
        "def separate_numerical(data):\n",
        "  cloned = data.copy()\n",
        "  \n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  numerical = cloned.drop(columns=object_list,axis=1)\n",
        "  \n",
        "  nonnumer = cloned[object_list]\n",
        "  \n",
        "  return numerical,nonnumer\n",
        "\n",
        "def separate_numerical_columns(data):\n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  numerical_list = list(data.select_dtypes(exclude=['object']).columns)\n",
        "  \n",
        "  return numerical_list, object_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66f87MDBlx75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "VISUALIZATION PRACTICE\n",
        "'''\n",
        "\n",
        "housing = strat_train_data.copy()\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        "\n",
        "#corr_matrix[\"median_house_value\"].sort_values()\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "#attributes = [\"median_house_value\",\"median_income\",\"total_rooms\",\"housing_median_age\"]\n",
        "\n",
        "#scatter_matrix(housing[attributes])\n",
        "\n",
        "#housing.plot(kind=\"scatter\",x=\"median_income\",y=\"median_house_value\",alpha=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH1pmhezl46s",
        "colab_type": "code",
        "outputId": "efa324ba-8240-4241-81a7-2fdb0886af8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "CORRELATION MATRIX PRACTICE\n",
        "'''\n",
        "'''\n",
        "housing[\"room_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
        "\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "\n",
        "housing[\"populations_per_household\"] = housing[\"population\"]/housing[\"households\"]\n",
        "'''\n",
        "\n",
        "#corr_matrix = housing.corr()\n",
        "#corr_matrix[\"median_house_value\"].sort_values()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhousing[\"room_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\\n\\nhousing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\\n\\nhousing[\"populations_per_household\"] = housing[\"population\"]/housing[\"households\"]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZyQNBQp_-bk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " OLD PIPE START HERE\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TViuwwHFp_Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "Imputer and Encoder practices\n",
        "'''\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def imputeData(data):\n",
        "  \n",
        "  ret_data = data.copy()\n",
        "  \n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  ret_data.drop(columns=object_list,axis=1,inplace=True)\n",
        "\n",
        "  imputer = SimpleImputer(strategy=\"median\")\n",
        "  imputer.fit(ret_data)\n",
        "  \n",
        "  X = imputer.transform(ret_data)\n",
        "\n",
        "  ret_data = pd.DataFrame(X,columns=ret_data.columns)\n",
        "  \n",
        "  #attach back the column with object\n",
        "  \n",
        "  wo_object =ret_data.copy()\n",
        "  \n",
        "  for column in object_list:\n",
        "    ret_data[column] = data[column]\n",
        "    \n",
        "  #return dataframe without object column and a frame WITH object column\n",
        "  return ret_data\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "#this will one-hot encode Panda Dataframe\n",
        "def encodeProx(data):\n",
        "  \n",
        "  ret_data = data.copy()\n",
        "  cat_encoder = OneHotEncoder(categories='auto')\n",
        "  #fill missing categorical value with just missing\n",
        "  \n",
        "  \n",
        "  object_list = list(ret_data.select_dtypes(include=['object']).columns)\n",
        "  '''for col in object_list:\n",
        "    ret_data[col].fillna('Missing',inplace=True)  \n",
        "    '''\n",
        "  #print(pd.isnull(ret_data).sum())\n",
        "  onehot = pd.get_dummies(ret_data,dummy_na=True)\n",
        "  #print(ret_data[\"ocean_proximity\"].values)\n",
        " \n",
        "  return onehot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5zXQaaHC77e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Transformer class inheritance practice\n",
        "\n",
        "'''\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n",
        "rooms_ix,bedrooms_ix,population_ix,households_ix = 3,4,5,6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  def __init__(self, add_bedrooms_per_room = True):\n",
        "    self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    \n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self,X,y=None):\n",
        "    rooms_per_household = X[:,rooms_ix] / X[:,households_ix]\n",
        "    population_per_household = X[:,population_ix]/X[:,households_ix]\n",
        "    if(self.add_bedrooms_per_room):\n",
        "      bedrooms_per_room  = X[:,bedrooms_ix] / X[:,rooms_ix]\n",
        "      return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n",
        "    else:\n",
        "      return np.c_[X,rooms_per_household,population_per_household]\n",
        "    \n",
        "    \n",
        "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
        "  def __init__(self,attribute_names):\n",
        "    self.attribute_names = attribute_names\n",
        "    print(attribute_names)\n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  def transform(self,X):\n",
        "    return X[self.attribute_names].values\n",
        "    \n",
        "\n",
        "class CategoricalOnehotEncoder(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  def __init__(self,encoding=\"onehot\"):\n",
        "    self.encoding = encoding\n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  def transform(self,X,y=None):\n",
        "    flatten_x = X.flatten()\n",
        "    x_series = pd.Series(flatten_x)\n",
        "    x_cat_enc,x_cat_arr = x_series.factorize()\n",
        "    encoder = OneHotEncoder()\n",
        "    x_1hot = encoder.fit_transform(x_cat_enc.reshape(-1,1))\n",
        "    return x_1hot\n",
        "    \n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdjzgt-HANHX",
        "colab_type": "text"
      },
      "source": [
        "# NEW PIPELINE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMug32NmtFq",
        "colab_type": "code",
        "outputId": "2f304fee-365a-4269-b63c-9a2164131a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "housing = strat_train_data.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
        "housing_labels = strat_train_data[\"median_house_value\"].copy()\n",
        "\n",
        "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
        "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1\n",
        "print(housing.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16512, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJdqQuYuAVZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def add_extra_features(X, add_bedrooms_per_room=True):\n",
        "    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
        "    population_per_household = X[:, population_ix] / X[:, household_ix]\n",
        "    if add_bedrooms_per_room:\n",
        "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "        return np.c_[X, rooms_per_household, population_per_household,\n",
        "                     bedrooms_per_room]\n",
        "    else:\n",
        "        return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "\n",
        "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
        "    list(housing.columns).index(col)\n",
        "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
        "\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num = housing.drop('ocean_proximity', axis=1)\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8SPbMgNMbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lllbDK97u33U",
        "colab_type": "code",
        "outputId": "0d65fda1-016a-4c13-d438-208c10739757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "SELECT AND TRAIN A MODEL\n",
        "'''\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#housing.drop(\"median_house_value\", axis=1,inplace=True)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared,housing_labels)\n",
        "\n",
        "# let's try the full preprocessing pipeline on a few training instances\n",
        "some_data = housing.iloc[:5]\n",
        "\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "\n",
        "some_data_prepared = full_pipeline.transform(some_data)\n",
        "\n",
        "\n",
        "#print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "\n",
        "lin_mse = mean_squared_error(housing_labels,housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "print(lin_rmse)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68628.19819848923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjiwKIevxojj",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l66cSNV-xoNQ",
        "colab_type": "code",
        "outputId": "66c17f58-923f-4e3c-bb2b-66899e5cde6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(housing_prepared,housing_labels)\n",
        "\n",
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels,housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "print(tree_rmse)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKvsw81ylGWm",
        "colab_type": "text"
      },
      "source": [
        "# K-FOLDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43OWMkP8RzI2",
        "colab_type": "code",
        "outputId": "d55d48e8-f20e-4587-8a87-15bb4b104034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def display_scores(scores):\n",
        "  print(\"Scores:\",scores)\n",
        "  print(\"Mean:\",scores.mean())\n",
        "  print(\"Standard deviation:\",scores.std())\n",
        "\n",
        "\n",
        "\n",
        "scores = cross_val_score(tree_reg,housing_prepared,housing_labels,\n",
        "                        scoring=\"neg_mean_squared_error\",cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)\n",
        "\n",
        "display_scores(tree_rmse_scores)\n",
        "\n",
        "lin_scores = cross_val_score(lin_reg,housing_prepared,housing_labels,\n",
        "                            scoring=\"neg_mean_squared_error\",cv=10)\n",
        "\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: [70450.41743142 65676.01451711 70023.82417394 68973.55249361\n",
            " 71153.17279186 74730.91579915 70900.78257078 70786.55920743\n",
            " 76545.81460179 70679.06471436]\n",
            "Mean: 70992.01183014434\n",
            "Standard deviation: 2802.914336584968\n",
            "Scores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
            " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
            " 71552.91566558 67665.10082067]\n",
            "Mean: 69052.46136345083\n",
            "Standard deviation: 2731.674001798344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tk9-A9QUjps",
        "colab_type": "text"
      },
      "source": [
        "#Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGabvbUxUimI",
        "colab_type": "code",
        "outputId": "4191849f-999c-41d1-b951-42230ea292d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "\n",
        "forest_reg.fit(housing_prepared,housing_labels)\n",
        "\n",
        "forest_scores = cross_val_score(forest_reg,housing_prepared,housing_labels,\n",
        "                               scoring=\"neg_mean_squared_error\",cv=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_JYbRzKTQiQ",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2LiacYFTQCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_reg = SVR(kernel=\"linear\")\n",
        "svm_reg.fit(housing_prepared, housing_labels)\n",
        "housing_predictions = svm_reg.predict(housing_prepared)\n",
        "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "svm_rmse = np.sqrt(svm_mse)\n",
        "svm_rmse"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}