{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homl_cp1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khlose/homl_ageron/blob/master/homl_cp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OTOINK8NSsJF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "import pandas as pd\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\",\"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
        "  if not os.path.isdir(housing_path):\n",
        "    os.makedirs(housing_path)\n",
        "  \n",
        "  tgz_path = os.path.join(housing_path,\"housing.tgz\")\n",
        "  \n",
        "  urllib.request.urlretrieve(housing_url,tgz_path)\n",
        "  housing_tgz = tarfile.open(tgz_path)\n",
        "  housing_tgz.extractall(path=housing_path)\n",
        "  housing_tgz.close()\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "  csv_path = os.path.join(housing_path,\"housing.csv\")\n",
        "  return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fetch_housing_data()\n",
        "housing = load_housing_data()\n",
        "\n",
        "\n",
        "#housing.head()\n",
        "\n",
        "#housing[\"ocean_proximity\"].value_counts()\n",
        "#housing.describe()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#housing.hist(bins=50,figsize=(20,15))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "  return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test(data,test_ratio,id_column):\n",
        "  \n",
        "  ids = data[id_column]\n",
        "  in_test_set = ids.apply(lambda id_:test_set_check(id_,test_ratio))\n",
        "  \n",
        "  return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#housing_with_id = housing.reset_index()\n",
        "#housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "#train,test = split_train_test(housing_with_id,0.2,\"index\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set,test_set = train_test_split(housing,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"]/1.5)\n",
        "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0,inplace=True)\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\n",
        "\n",
        "for train_index,test_index in split.split(housing,housing[\"income_cat\"]):\n",
        "  strat_train_data = housing.loc[train_index]\n",
        "  strat_test_data = housing.loc[test_index]\n",
        "\n",
        "  \n",
        "print(strat_train_data.count())  \n",
        "\n",
        "\n",
        "#basically loop twice, first loop is start_train_data loop\n",
        "#and second is strat_test_data loop\n",
        "for set_ in (strat_train_data,strat_test_data):\n",
        "  print(set_.count())\n",
        "  \n",
        "  set_.drop(\"income_cat\",axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66f87MDBlx75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "housing = strat_train_data.copy()\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        "\n",
        "#corr_matrix[\"median_house_value\"].sort_values()\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "#attributes = [\"median_house_value\",\"median_income\",\"total_rooms\",\"housing_median_age\"]\n",
        "\n",
        "#scatter_matrix(housing[attributes])\n",
        "\n",
        "housing.plot(kind=\"scatter\",x=\"median_income\",y=\"median_house_value\",alpha=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pH1pmhezl46s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "housing[\"room_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
        "\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "\n",
        "housing[\"populations_per_household\"] = housing[\"population\"]/housing[\"households\"]\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TViuwwHFp_Ia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def imputeData(data):\n",
        "  \n",
        "  ret_data = data.copy()\n",
        "  \n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  ret_data.drop(columns=object_list,axis=1,inplace=True)\n",
        "\n",
        "  imputer = SimpleImputer(strategy=\"median\")\n",
        "  imputer.fit(ret_data)\n",
        "  \n",
        "  X = imputer.transform(ret_data)\n",
        "\n",
        "  ret_data = pd.DataFrame(X,columns=ret_data.columns)\n",
        "  \n",
        "  #attach back the column with object\n",
        "  \n",
        "  wo_object =ret_data.copy()\n",
        "  \n",
        "  for column in object_list:\n",
        "    ret_data[column] = data[column]\n",
        "    \n",
        "  #return dataframe without object column and a frame WITH object column\n",
        "  return wo_object,ret_data\n",
        "\n",
        "def objectDataProc(data):\n",
        "  ret_data = data.copy()\n",
        "  encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "  encoder.fit(ret_data)\n",
        "  \n",
        "  housing_cat_1hot = encoder.transfor(ret_data)\n",
        "  print(housing_cat_1hot.describe())\n",
        "  \n",
        "  return housing_cat_1hot\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wc6SrHWGpddm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "f3692f1d-1673-4bf1-e206-cd773f326628"
      },
      "cell_type": "code",
      "source": [
        "#reset\n",
        "housing = strat_train_data.copy()\n",
        "\n",
        "housing_pred = strat_train_data.drop(\"median_house_value\",axis=1)\n",
        "housing_label = strat_train_data[\"median_house_value\"].copy()\n",
        "\n",
        "\n",
        "housing_tr_nObj, housing_tr_reg = imputeData(housing_pred)\n",
        "\n",
        "print(housing_tr_reg[\"ocean_proximity\"][13])\n",
        "\n",
        "#print(housing_tr_reg[\"ocean_proximity\"].isna())\n",
        "\n",
        "housing_cat = housing[\"ocean_proximity\"]\n",
        "housing_cat_encoded,housing_categories = housing_cat.factorize(na_sentinel=-2)\n",
        "\n",
        "print(housing_categories)\n",
        "\n",
        "print(housing_cat_encoded[13])\n",
        "\n",
        "unique, counts = np.unique(housing_cat_encoded, return_counts=True)\n",
        "\n",
        "dict(zip(unique, counts))\n",
        "#data_1hot = objectDataProc(housing_tr_reg)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nan\n",
            "Index(['<1H OCEAN', 'NEAR OCEAN', 'INLAND', 'NEAR BAY', 'ISLAND'], dtype='object')\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 7276, 1: 2124, 2: 5263, 3: 1847, 4: 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}