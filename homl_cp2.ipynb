{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homl_cp1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khlose/homl_ageron/blob/master/homl_cp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTOINK8NSsJF",
        "colab_type": "code",
        "outputId": "36d40fcc-ab07-4859-f1f4-b8241392160e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "'''\n",
        "DATA LOADING AND SPLITTING PRACTICE\n",
        "'''\n",
        "\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "import pandas as pd\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\",\"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL,housing_path=HOUSING_PATH):\n",
        "  if not os.path.isdir(housing_path):\n",
        "    os.makedirs(housing_path)\n",
        "  \n",
        "  tgz_path = os.path.join(housing_path,\"housing.tgz\")\n",
        "  \n",
        "  urllib.request.urlretrieve(housing_url,tgz_path)\n",
        "  housing_tgz = tarfile.open(tgz_path)\n",
        "  housing_tgz.extractall(path=housing_path)\n",
        "  housing_tgz.close()\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "  csv_path = os.path.join(housing_path,\"housing.csv\")\n",
        "  return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fetch_housing_data()\n",
        "housing = load_housing_data()\n",
        "\n",
        "\n",
        "#housing.head()\n",
        "\n",
        "#housing[\"ocean_proximity\"].value_counts()\n",
        "#housing.describe()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#housing.hist(bins=50,figsize=(20,15))\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from zlib import crc32\n",
        "\n",
        "def test_set_check(identifier, test_ratio):\n",
        "  return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test(data,test_ratio,id_column):\n",
        "  \n",
        "  ids = data[id_column]\n",
        "  in_test_set = ids.apply(lambda id_:test_set_check(id_,test_ratio))\n",
        "  \n",
        "  return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#housing_with_id = housing.reset_index()\n",
        "#housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "#train,test = split_train_test(housing_with_id,0.2,\"index\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set,test_set = train_test_split(housing,test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"]/1.5)\n",
        "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0,inplace=True)\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2, random_state=42)\n",
        "\n",
        "for train_index,test_index in split.split(housing,housing[\"income_cat\"]):\n",
        "  strat_train_data = housing.loc[train_index]\n",
        "  strat_test_data = housing.loc[test_index]\n",
        "\n",
        "  \n",
        "print(strat_train_data.count())  \n",
        "\n",
        "\n",
        "#basically loop twice, first loop is start_train_data loop\n",
        "#and second is strat_test_data loop\n",
        "for set_ in (strat_train_data,strat_test_data):\n",
        "  #print(set_.count())\n",
        "  \n",
        "  set_.drop(\"income_cat\",axis=1,inplace=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "longitude             16512\n",
            "latitude              16512\n",
            "housing_median_age    16512\n",
            "total_rooms           16512\n",
            "total_bedrooms        16354\n",
            "population            16512\n",
            "households            16512\n",
            "median_income         16512\n",
            "median_house_value    16512\n",
            "ocean_proximity       16512\n",
            "income_cat            16512\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxDmb9efRyGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Data extraction practice\n",
        "'''\n",
        "\n",
        "#separating numerical and non-numerical data\n",
        "\n",
        "def separate_numerical(data):\n",
        "  cloned = data.copy()\n",
        "  \n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  numerical = cloned.drop(columns=object_list,axis=1)\n",
        "  \n",
        "  nonnumer = cloned[object_list]\n",
        "  \n",
        "  return numerical,nonnumer\n",
        "\n",
        "def separate_numerical_columns(data):\n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  numerical_list = list(data.select_dtypes(exclude=['object']).columns)\n",
        "  \n",
        "  return numerical_list, object_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66f87MDBlx75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "VISUALIZATION PRACTICE\n",
        "'''\n",
        "\n",
        "housing = strat_train_data.copy()\n",
        "\n",
        "corr_matrix = housing.corr()\n",
        "\n",
        "#corr_matrix[\"median_house_value\"].sort_values()\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "#attributes = [\"median_house_value\",\"median_income\",\"total_rooms\",\"housing_median_age\"]\n",
        "\n",
        "#scatter_matrix(housing[attributes])\n",
        "\n",
        "#housing.plot(kind=\"scatter\",x=\"median_income\",y=\"median_house_value\",alpha=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH1pmhezl46s",
        "colab_type": "code",
        "outputId": "f1dc744a-e461-47c5-e22a-e78147e608c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "CORRELATION MATRIX PRACTICE\n",
        "'''\n",
        "'''\n",
        "housing[\"room_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
        "\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "\n",
        "housing[\"populations_per_household\"] = housing[\"population\"]/housing[\"households\"]\n",
        "'''\n",
        "\n",
        "#corr_matrix = housing.corr()\n",
        "#corr_matrix[\"median_house_value\"].sort_values()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhousing[\"room_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\\n\\nhousing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\\n\\nhousing[\"populations_per_household\"] = housing[\"population\"]/housing[\"households\"]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZyQNBQp_-bk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " OLD PIPE START HERE\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TViuwwHFp_Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "Imputer and Encoder practices\n",
        "'''\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def imputeData(data):\n",
        "  \n",
        "  ret_data = data.copy()\n",
        "  \n",
        "  object_list = list(data.select_dtypes(include=['object']).columns)\n",
        "  ret_data.drop(columns=object_list,axis=1,inplace=True)\n",
        "\n",
        "  imputer = SimpleImputer(strategy=\"median\")\n",
        "  imputer.fit(ret_data)\n",
        "  \n",
        "  X = imputer.transform(ret_data)\n",
        "\n",
        "  ret_data = pd.DataFrame(X,columns=ret_data.columns)\n",
        "  \n",
        "  #attach back the column with object\n",
        "  \n",
        "  wo_object =ret_data.copy()\n",
        "  \n",
        "  for column in object_list:\n",
        "    ret_data[column] = data[column]\n",
        "    \n",
        "  #return dataframe without object column and a frame WITH object column\n",
        "  return ret_data\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "#this will one-hot encode Panda Dataframe\n",
        "def encodeProx(data):\n",
        "  \n",
        "  ret_data = data.copy()\n",
        "  cat_encoder = OneHotEncoder(categories='auto')\n",
        "  #fill missing categorical value with just missing\n",
        "  \n",
        "  \n",
        "  object_list = list(ret_data.select_dtypes(include=['object']).columns)\n",
        "  '''for col in object_list:\n",
        "    ret_data[col].fillna('Missing',inplace=True)  \n",
        "    '''\n",
        "  #print(pd.isnull(ret_data).sum())\n",
        "  onehot = pd.get_dummies(ret_data,dummy_na=True)\n",
        "  #print(ret_data[\"ocean_proximity\"].values)\n",
        " \n",
        "  return onehot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5zXQaaHC77e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Transformer class inheritance practice\n",
        "\n",
        "'''\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "\n",
        "rooms_ix,bedrooms_ix,population_ix,households_ix = 3,4,5,6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  def __init__(self, add_bedrooms_per_room = True):\n",
        "    self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    \n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  \n",
        "  def transform(self,X,y=None):\n",
        "    rooms_per_household = X[:,rooms_ix] / X[:,households_ix]\n",
        "    population_per_household = X[:,population_ix]/X[:,households_ix]\n",
        "    if(self.add_bedrooms_per_room):\n",
        "      bedrooms_per_room  = X[:,bedrooms_ix] / X[:,rooms_ix]\n",
        "      return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]\n",
        "    else:\n",
        "      return np.c_[X,rooms_per_household,population_per_household]\n",
        "    \n",
        "    \n",
        "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
        "  def __init__(self,attribute_names):\n",
        "    self.attribute_names = attribute_names\n",
        "    print(attribute_names)\n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  def transform(self,X):\n",
        "    return X[self.attribute_names].values\n",
        "    \n",
        "\n",
        "class CategoricalOnehotEncoder(BaseEstimator, TransformerMixin):\n",
        "  \n",
        "  def __init__(self,encoding=\"onehot\"):\n",
        "    self.encoding = encoding\n",
        "  def fit(self,X,y=None):\n",
        "    return self\n",
        "  def transform(self,X,y=None):\n",
        "    flatten_x = X.flatten()\n",
        "    x_series = pd.Series(flatten_x)\n",
        "    x_cat_enc,x_cat_arr = x_series.factorize()\n",
        "    encoder = OneHotEncoder()\n",
        "    x_1hot = encoder.fit_transform(x_cat_enc.reshape(-1,1))\n",
        "    return x_1hot\n",
        "    \n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdjzgt-HANHX",
        "colab_type": "text"
      },
      "source": [
        "# NEW PIPELINE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMug32NmtFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73f7f129-77b5-4db1-ed59-ac72c72274a9"
      },
      "source": [
        "housing = strat_train_data.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
        "housing_labels = strat_train_data[\"median_house_value\"].copy()\n",
        "\n",
        "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
        "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1\n",
        "print(housing.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16512, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJdqQuYuAVZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8SPbMgNMbR",
        "colab_type": "code",
        "outputId": "11e470aa-13d5-4d69-8042-36b9e6fc4f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-3bbe0f6f25c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhousing_prepared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         raise ValueError(\"No valid specification of the columns. Only a \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         raise ValueError(\"No valid specification of the columns. Only a \"\n",
            "\u001b[0;31mValueError\u001b[0m: 'median_house_value' is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lllbDK97u33U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "SELECT AND TRAIN A MODEL\n",
        "'''\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#housing.drop(\"median_house_value\", axis=1,inplace=True)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared,housing_labels)\n",
        "\n",
        "# let's try the full preprocessing pipeline on a few training instances\n",
        "some_data = housing.iloc[:5]\n",
        "\n",
        "some_labels = housing_labels.iloc[:5]\n",
        "\n",
        "some_data_prepared = new_full_pipeline.transform(some_data)\n",
        "\n",
        "\n",
        "#print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "\n",
        "lin_mse = mean_squared_error(housing_labels,housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "print(lin_rmse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjiwKIevxojj",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l66cSNV-xoNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(housing_prepared,housing_labels)\n",
        "\n",
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels,housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "print(tree_rmse)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}